import { NextRequest } from "next/server";
import { createClient } from "@supabase/supabase-js";
import OpenAI from "openai";

const {
  OPENAI_API_KEY,
  SUPABASE_URL,
  SUPABASE_SERVICE_ROLE_KEY,
  CUSTOM_GPT_BUCKET,
  CUSTOM_GPT_FOLDER,
  CUSTOM_GPT_INSTRUCTIONS = "Instructions/instructions.txt",
  CUSTOM_GPT_KB_FOLDER = "Knowledge_Base",
} = process.env;

const MAX_DOC_LENGTH = 1500; // chars per doc

export async function POST(req: NextRequest) {
  try {
    if (
      !OPENAI_API_KEY ||
      !SUPABASE_URL ||
      !SUPABASE_SERVICE_ROLE_KEY ||
      !CUSTOM_GPT_BUCKET ||
      !CUSTOM_GPT_FOLDER
    ) {
      return new Response(JSON.stringify({ error: "Missing env vars" }), {
        status: 500,
      });
    }

    const { message } = await req.json();
    if (!message || typeof message !== "string") {
      return new Response(
        JSON.stringify({ error: "Missing or invalid 'message'." }),
        { status: 400 }
      );
    }

    const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);

    // 1) Load instructions
    const instructionsPath = `${CUSTOM_GPT_FOLDER}/${CUSTOM_GPT_INSTRUCTIONS}`;
    const { data: instFile, error: instErr } = await supabase
      .storage
      .from(CUSTOM_GPT_BUCKET)
      .download(instructionsPath);

    if (instErr || !instFile) {
      return new Response(
        JSON.stringify({ error: "Instructions file not found." }),
        { status: 500 }
      );
    }
    const instructions = await instFile.text();

    // 2) List KB files
    const kbFolderPath = `${CUSTOM_GPT_FOLDER}/${CUSTOM_GPT_KB_FOLDER}`;
    const { data: kbFiles, error: kbErr } = await supabase
      .storage
      .from(CUSTOM_GPT_BUCKET)
      .list(kbFolderPath);

    if (kbErr || !kbFiles) {
      return new Response(
        JSON.stringify({ error: "Knowledge base folder not found." }),
        { status: 500 }
      );
    }

    // 3) Download KB docs
    const docs: { name: string; text: string }[] = [];
    for (const f of kbFiles) {
      if (f.name.endsWith(".txt") || f.name.endsWith(".md")) {
        const { data: fileRes } = await supabase
          .storage
          .from(CUSTOM_GPT_BUCKET)
          .download(`${kbFolderPath}/${f.name}`);
        if (fileRes) {
          docs.push({
            name: f.name,
            text: (await fileRes.text()).slice(0, MAX_DOC_LENGTH),
          });
        }
      }
    }

    // 4) Score docs
    const keywords = message
      .toLowerCase()
      .split(/\W+/)
      .filter((w) => w.length > 2);
    const scoredDocs = docs
      .map((doc) => ({
        ...doc,
        score: keywords.reduce(
          (acc, kw) =>
            acc + (doc.text.toLowerCase().includes(kw) ? 1 : 0),
          0
        ),
      }))
      .sort((a, b) => b.score - a.score)
      .slice(0, 3);

    const contextText = scoredDocs
      .map((doc) => `---\n${doc.name}\n${doc.text}`)
      .join("\n\n");

    const systemPrompt =
      instructions +
      "\n\nRULE: If context is insufficient, ask a clarifying question.";

    const userPrompt = `${message}\n\nContext:\n${contextText}`;

    // 5) Call OpenAI
    const openai = new OpenAI({ apiKey: OPENAI_API_KEY });
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      temperature: 0.2,
    });

    const reply =
      completion.choices?.[0]?.message?.content ??
      "No reply generated by OpenAI.";

    return new Response(JSON.stringify({ reply }), { status: 200 });
  } catch (err: any) {
    console.error("GPT error:", err);
    return new Response(
      JSON.stringify({ error: err.message || "Internal Server Error" }),
      { status: 500 }
    );
  }
}